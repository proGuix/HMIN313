\documentclass[12pt]{report}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{tikz}
\usetikzlibrary{shapes,arrows}
\usepackage{hyperref}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}
\usepackage{tabularx}
\usepackage{pgfplots}
\usepackage{filecontents}

\pgfplotsset{every linear axis/.append style={
    compat=1.8,
    /pgf/number format/.cd,
    use comma,
    1000 sep={\,}}}

\renewcommand\thesection{}
\renewcommand\thesubsection{}

\begin{document}

\title{Persistance de données RDF : mini-moteur}
\author{Guillaume VELAY -- Badr HERRESS}
\date{\today}

\maketitle

\tableofcontents
\newpage

\section{Introduction}
Nous avons implémenté un mini-moteur qui renvoie les résultats correspondants à une requête étoile sur des données RDF. Ce système traite les données et les requêtes en mémoire vive, il est implémenté en Java. 

Nous nous sommes donné le défi de résoudre ce problème avec l'approche des graphes.

Le projet est disponible vers le lien github suivant \url{https://github.com/proGuix/HMIN313}.

\section{Implémentation}

Nous avons suivi toutes les étapes du cours concernant les graphes mais nous l'avons adapté aux requêtes étoiles. Nous avons aussi incorporé nos propres optimisations et indexes pour rendre le système le plus efficace possible.

\subsection{Parsage triplets RDF}

Au commencement du programme, on vous demande de choisir quel fichier de triplets rdf choisir. La classe FileRDFParser va se charger d'enregistrer chaque uri et littéral différents dans un dictionnaire.

\subsection{Dictionnaire}

Une fois le parsage du fichier des triplets rdf fait, on récupère le dictionnaire sous la forme d'un objet Dictionary de FileRDFParser. Cet objet contient le graphe des données GraphData. A chaque fois qu'un nouveau triplet est parsé, on enregistre les uri, littéraux et également on construit le graphe des données.
Le dictionnaire utilise une HashMap avec pour clé un entier et comme valeur une chaine de caractères.

\subsection{Graphe de données}

Cet objet est représenté par un GraphData. Quand on enregistre les triplets sous forme de graphe, on fusionne les relations qui possède le même objet, nous avons donc des relations possédant plusieurs prédicats, les prédicats de chaque relation sont triés selon l'ordre du dictionnaire car dans les données nous traitons seulement des entiers car plus simple de manipulation et de comparaison. Le fait d'avoir des relations qui possèdent des prédicats triés améliore la rapidité de la recherche d'un voisin selon un ensemble de prédicats.

\subsection{Statistiques sur les données}

Dans le graphe des données, nous calculons pour chaque prédicats différents son nombre d'occurrence que nous enregistrons dans une HashMap. C'est utile quand on veut restreindre la recherche d'une donnée possédant un ensemble de prédicat. La recherche va s'effectuer d'abord sur les prédicats les moins occurrents.

\subsection{Arbre des préfixes des relations}

A partir du graphe des données, nous avons construit un objet PrefixTreeData qui trie dans un arbre les préfixes correspondant aux relations dans le graphe des données. Cette objet est une idée qui nous est venue à l'esprit pour récupérer l'ensemble des noeuds qui possèdent un ensemble de prédicats donné. La recherche est alors plus rapide que si nous l'avions fait directement dans le graphe des données en parcourant les sommets du graphe ou les relations.

\subsection{Arbre de voisinage FP-TREE}

L'arbre de voisinage est représenté par l'objet GraphNeighboorBis. Il s'agit d'un FP-TREE. C'est un arbre de préfixe sur les relations sortantes d'un noeud donné, il enregistre tous les voisins accessible à partir d'un ensemble de prédicats donné. Ce arbre possède également des linkedList, il s'agit pour chaque prédicat de tracer un chemin reliant le même prédicat. La recherche d'un voisin selon un ensemble de prédicats $p_{1},...,p_{n}$ va donc constituer une comparaison sur chaque prédicats de chaque linkedList correspondant aux prédicats $p_{1},...,p_{n}$. Une optimisation consiste à trier l'arbre de voisinage en largeur et en profondeur selon l'ordre des prédicats dans le dictionnaire, cela à pour but de créer naturellement des linkedLink ordonnées.

L'objet qui contient tous les arbres de voisinages de chaque noeud du graphe des données s'appelle NeighIndexBis, il les contient tous dans une HashMap.

\subsection{Parsage d'une requête étoile et pré-traitements}

Une fois que le graphe des données est chargé, avec l'arbre des préfixes et les arbres de voisinages, le programme va demander un document de requêtes à charger.

L'objet qui parse une requête étoile est QueryParser. Les pré-traitements effectués sont semblables à celui de la création du graphe de données : des branches de la requête peuvent être fusionnées si ces branches ont le même objet et les prédicats des branches sont triés selon l'ordre du dictionnaire. Lorsque nous créons le graphe de la requête étoile nous établissons également  un ordre sur la longueur des branches de la plus longue à la plus petite. Cela va nous servir pour obtenir l'ordre final de traitement des branches dans la résolution.

\subsection{Graphe de la requête étoile et mesure de la sélectivité des branches}

L'objet correspondant au graphe de la requête étoile est QueryGraph.

Une fois que le parsage de la requête est effectué ainsi que l'ordre initial des du traitement des branches, nous allons définir l'ordre final en jouant sur le nombre d'occurrences d'un prédicat dans les données. Nous avons crée une heuristique qui nous a fourni un ordre que nous avons conjecturé comme correct par rapport à un ordre total sur la sélectivité des prédicats. 

Voici un exemple, nous avons dans l'ordre de la plus petite à la plus grande occurrence ces prédicats présents dans la requête étoile : $p_{3},p_{1},p_{2}$ donc nous sélectionnons en premier les branches qui contiennent $p_{3}$ sachant que les branches sont aussi triées par longueur de la plus grande à la plus petite, puis les branches restantes contenant $p_{1}$ et enfin $p_{2}$.

L'algorithme qui rendrait un ordre total prendrai en premier les branches qui contiennent $p_{3}$ puis les trierai suivant le nombre d'occurrence de $p_{1}$ et $p_{2}$ mais ce tri est possible que si on touche aux données car il faudrait regarder d'abord dans l'arbre des préfixes des relations, puis pour chacun des sujets trouvés il faudrait regarder dans leur arbre de voisinage et compter pour $p_{1}$ et $p_{2}$ les occurrences d'objets. 

Cependant si on avait plus de statistiques sur la distribution des données, on pourrait améliorer l'ordre qu'on obtient sans toucher aux données.

Finalement, sachant que le traitement des requêtes et l'ordonnancement des branches peut drastiquement impacter sur le temps de résolution, nous aurions aimé étudier plus en profondeur d'autres heuristiques pour avoir le meilleur compromis entre le traitement d'une requête et le temps de résolution.

\subsection{Résolution}

La résolution se fait dans l'objet Resolution.
Une fois que tous nos éléments cités précédemment sont créés, nous pouvons commencer l'algorithme. Celui ci prend la première branche de la requête étoile selon l'ordre précédemment cité et cherche tous les noeuds qui possèdent les mêmes prédicats que cette branche dans l'arbre des préfixes. Nous obtenons donc l'ensemble des noeuds initiaux sur lesquels nous allons effectuer la suite de l'algorithme. Toutes les solutions à la requête sont incluses à l'intérieur de cet ensemble. Ensuite, pour chacun de ces noeuds on vérifie l'existence de toutes les branches de la requête (prédicats et objets) à ce noeud grâce à l'arbre de voisinage. Si et seulement si toutes les branches correspondent à ce noeud alors il est solution.

La grande difficulté dans cet algorithme est de restreindre au maximum l'ensemble initial de recherche, plus il est réduit et moins il est coûteux en temps.

\section{Optimisations}

En ce qui concerne le FP-TREE (arbre de voisinage), nous l'avions initialement implémenté naïvement comme dans le cours. Notre première réflexion sur une optimisation concernait les linkedList (lignes rouges), nous pensions que si nous n'avions pas des listes mais des graphes qui reliraient les prédicats entre eux par un lien d'inclusion (liste de prédicats inclus dans une autre) nous gagnerions du temps de calcul dans la recherche d'un voisin. Mais après une discussion avec notre professeur, celui-ci nous a dissuadé de faire de la sorte car les listes de prédicats des branches n'étaient pas forcément contiguës. Mais nous aurions pu quand même effectuer cette optimisation en changeant le lien d'inclusion par le lien de sous ensemble d'une liste de prédicats qui contient un sous ensemble d'une autre liste de prédicats, mais la complexité pour la création de ceci devenait exponentielle sur le nombre de branches.

Au bout de la discussion, notre professeur nous a donné une optimisation pour la recherche d'un voisin dans le FP-TREE, il s'agissait d'implémenter l'arbre de voisinage non pas avec une structure arborescente mais en utilisant des tableaux qui stockeraient pour chaque noeud de l'arbre son begin/end. La grande propriété de cette notation est qu'il est possible de savoir si deux noeuds $n_{1}$ et $n_{2}$ sont soit l'un ancêtre de l'autre, soit l'un dans une branche de gauche ou de droite par rapport à l'autre par des comparaisons numériques des begin/end. Si $begin_{2}$ > $begin_{1}$ et $end_{2}$ < $end_{1}$ alors $n_{1}$ est ancêtre de $n_{2}$.
Si $begin_{2}$ > $begin_{1}$ et $end_{2}$ > $end_{1}$ alors $n_{1}$ est dans une branche à gauche de celle de $n_{2}$. Si $begin_{2}$ < $begin_{1}$ et $end_{2}$ < $end_{1}$ alors $n_{1}$ est dans une branche à droite de celle de $n_{2}$. L'optimisation permet donc d'éviter des vérifications en parcourant les branches de l'arbre.

Nous avions aussi pensez à mixer notre algorithme avec une méthode par dichotomie et selon la distribution des données, cela auraient peut être été encore plus rapide.

Nous avions une autre optimisation, celle d'implémenter la solution avec le langage C++ pour ce qui est de la gestion de la mémoire, malheureusement nous n'avons pas eu assez de temps.

\section{Difficultés}

La principale difficulté que nous avons rencontré se base sur le temps d'étude. Si nous avions eu plus de temps nous aurions par exemple choisit d'utiliser plutôt des HashMap que des ArrayList dans certains cas. Ou par exemple l'étude d'autres heuristiques qui nous aurait permis de gagner du temps de résolution en se basant sur la distribution des données. 

Nous avons aussi pris du temps pour comprendre d'abord la solution par l'approche des graphes.

Le code actuel n'est pas factorisé, vue le nombre d'objet que nous devions implémenter. Nous n'avons pas pris le temps d'enlever ce qui ne sert à rien car nous avons ré-implémenté des objets par manque d'efficacité.


\section{Utilisation du programme}

Notre application s'appelle \textbf{app.jar}. Si vous voulez accéder au lien github de notre projet, les informations pour compiler et exécuter le programme y sont inscrites dans le README en anglais. Sinon ci-joint au rapport vous trouverez le projet déjà prêt à l'emploi. 

La commande pour exécuter le programme est \textbf{java -jar app.jar} et laissez vous guider. Les fichiers de triplets RDF se trouve dans le dossier \textbf{test/dataset}, le programme vous donne le choix de prendre entre 100K.rdf et 500K.rdf. Ensuite vous devez attendre que le programme charge les données, il vous donne à chaque chaque instant le nombre de triplets qu'il a déjà chargés. 

Une fois que les données sont créées, vous devez choisir le fichier de requêtes à exécuter, les fichiers se trouvent dans \textbf{test/queries}, il y a en a douze, chacun de ces fichiers possèdent cent requêtes.

Le programme vous donne une trace des résultats en console, dès que toutes les requêtes d'un fichier sont exécutées, le programme vous redemande si vous voulez exécuter un autre fichier de requêtes.

Quand les requêtes d'un fichier sont exécutées, le programme écrit les résultats dans le dossier \\
\textbf{test/queries\_result\_and\_time}. Par exemple pour le fichier de requêtes \\Q\_1\_includes.queryset le programme renvoient les fichiers Q\_1\_includes.queryset\_result.csv et Q\_1\_includes.queryset\_time.csv. Pour chacun de ces deux fichiers, chaque ligne numéro $N$ correspond au résultat ou au temps (en ms) de la requête numéro $N$.

\section{Benchmarks}
Durant ce projet et afin de réaliser nos tests nous avons utilisé un benchmark standard, qui est WatDiv.\\
Test possible pour chaque type de benchmark.\\
WatDiv est un benchmark fait pour mesurer les performances d’un gestionnaire de données rdf. Il est composé de deux  générateurs un pour les données et le second pour les requêtes sur ce jeu de données. WatDiv permet aussi aux utilisateur de créer leurs propres jeux de données en paramétrant les entités et les associations.\\

Pour nos tests nous avons utilisé le benchmark pré-configuré du Moodle : 100K et 500K de triplets pour les données et 12 fichiers de 100 requêtes.\\



\section{Outils utilisés}

Les tests ont été réalisés sur deux ordinateurs différents : 
\begin{itemize}
\item MAC OS X 10.11.6, 1.6 GHZ Intel Core i5, 8 Go RAM, 121 GO SSD.
\item Linux Ubuntu 14.04 LTS, Intel Core i5, 4 Go RAM, 750 Go.
\end{itemize}
On aussi utilisé l'outil WatDiv afin de générer des données et des requêtes pour le test de notre programme.

\section{Les métriques}

Pour ces tests on va se baser sur deux métriques :
\begin{itemize}
\item Le temps de chargement des données par le programmes.
\item Le temps d’exécution et de réponses pour les requêtes effectuées par le programme.
\end{itemize}

On va considérer les facteurs suivants :\\\\
\begin{tabular}{|>{\centering\arraybackslash}p{5cm}|>{\centering\arraybackslash}p{5cm}|>{\centering\arraybackslash}p{5cm}|}
  \hline
  \bf CPU & 1.6 GHZ Intel Core i5 & 1.6 GHZ Intel Core i5  \\
  \hline
  \bf RAM & 8 Go & 4 Go \\
  \hline
  \bf La taille des données & 100 000 triplets & 500 000 triplets \\
  \hline
  \bf OS & MAC OS  X &  Linux Ubuntu 14.04\\
  \hline
\end{tabular}
\\
\\
Nous pensons que la taille des données sera la facteur le plus important suivie de la RAM et la CPU et enfin l’OS. Et nous pouvons les répartir en facteurs principaux (RAM et Data size) et secondaires (CPU et OS)

\section{Vérification et correction de notre système}
Afin de nous assurer du bon fonctionnement de notre système, nous avons effectué les mêmes requêtes sur le même jeux de données mais cette fois-ci en utilisant Jena. Dans le dossier \textbf{completude/}, vous trouverez une classe Complétude qui compare les résultats de deux fichers : jena\_results.csv et app\_results.\\

La procédure est la suivante :
\begin{itemize}
\item on entre les résultats d'une requete de jena dans un dictionnaire.
\item pour chaque resultat d'une requete de notre application, on regarde si le resultat a déjà eté traité comme doublon.
\item s'il n'existe pas déjà comme doublon alors on vérifie si le résultat existe dans le dictionnaire.
\item s'il existe dans le dictionnaire, on met la valeur dans un ensemble ensExist, s'il ne contient pas on entre la valeur dans ensNExist.\\
\end{itemize}

On a ainsi l'ensemble ensExist des résultats qui sont vérifiés, l'ensemble ensNExist des résultats non vérifiés et enfin l'ensemble ensDbls des résultats doublons.\\

Nous avons pu vérifié que notre système est à 100\% complet sans doublons sur les 1200 requetes pour les dataset 100K et 500K.


\section{Technique d’évaluation}

Nous pensons que les mesures cold, warm seront plus intéressants à utiliser dans la métrique qui concerne le temps d’exécution d’une requêtes, en effet lors de cette opération le système va chercher l’information dans la mémoire de l’ordinateur. 

Afin de réaliser nos mesures, nous avons décider d’opérer de la manière :
\begin{itemize}
\item Nous exécutons notre système, puis celui du groupe avec qui nous devons comparer et enfin celui de Jena sur deux jeu de données de tailles différentes (100.000 et 500.000 triplets).
\item Nous exécutons ensuite les 1200 requêtes sur chacun d’eux. 
\item Nous obtenons alors 6 fichiers csv représentant chacun le temps d'exécutions des 1200 requêtes pour un système et une taille de données
\item Cette opération sera réalisée 5 fois, une au démarrage de l’ordinateur («cold») et  quatres autres après au moins une exécution («warm»)
\item Nous obtenons ainsi 30 fichiers avec chacun 1200 résultats. Nous parcourrons chacun des fichiers afin de réaliser une moyenne artihmétique du temps d'éxecution d'une requête.
\item Nous obtenons donc 10 résultats pour chacun des systèmes, représentés dans les tableaux suivants : 
  \\
  \\
  Les résultats pour 100.000 triplets.
  \\
  \begin{tabular}{|>{\centering\arraybackslash}p{3cm}||>{\centering\arraybackslash}p{2cm}|>{\centering\arraybackslash}p{2cm}|>{\centering\arraybackslash}p{2cm}|>{\centering\arraybackslash}p{2cm}|>{\centering\arraybackslash}p{2cm}|}
    \hline
    \bf Système & \bf Temps 1 "Cold" & \bf Temps 2 "Warm" & \bf Temps 3 "Warm" & \bf Temps 4 "Warm" & \bf Temps 5 "Warm" \\
    \hline
    Notre système & $1.5016 ms$ & $1.4775 ms$ & $1.3883 ms$  & $1.3558 ms$ & $1.3866 ms$\\
    \hline
    Jena& $1.0892 ms$ & $0.9892 ms$ & $1.1584 ms$  & $1.0261 ms$ & $0.97 ms$ \\
    \hline
    Système de Florient Dieu & $0.6388ms$ & $0.5578ms$ &  $0.5476ms$ & $0.4967ms$  & $0.5459ms$ \\
    \hline
  \end{tabular}
  \\
  \\
  Les résultats pour 500.000 triplets.
  \\
  \begin{tabular}{|>{\centering\arraybackslash}p{3cm}||>{\centering\arraybackslash}p{2cm}|>{\centering\arraybackslash}p{2cm}|>{\centering\arraybackslash}p{2cm}|>{\centering\arraybackslash}p{2cm}|>{\centering\arraybackslash}p{2cm}|}
    \hline
    \bf Système & \bf Temps 1 "Cold" & \bf Temps 2 "Warm" & \bf Temps 3 "Warm" & \bf Temps 4 "Warm" & \bf Temps 5 "Warm" \\
    \hline
    Notre système & $5.9758 ms$ & $5.9366 ms$ & $5.8858 ms$  & $5.8691 ms$ & $5.8875 ms$\\
    \hline
    Jena& $1.8723 ms$ & $1.65 ms$ & $1.4592 ms$  & $1.7138 ms$ & $1.5723 ms$ \\
    \hline
    Système de Florient Dieu & $1.7689ms$ & $1.7381ms$ & $1.6690ms$ & $1.6072ms$ & $1.6061ms$  \\
    \hline
  \end{tabular}
\end{itemize}
\section{Experiment factoriel}


Nous allons commencer par réaliser un expriment factoriel $2^2$, en utilisant le facteur de la mémoire et celui de la taille de données. Le temps affiché représente le temps d'éxecution des 1200 requêtes.
\\\\
\begin{tabular}{|>{\centering\arraybackslash}p{5cm}|>{\centering\arraybackslash}p{5cm}|>{\centering\arraybackslash}p{5cm}|}
  \hline
  & \bf 4 GB mémoire & \bf 8 GB mémoire  \\
  \hline
  \bf 100.000 triplets & $1569 ms$ & $1669 ms$ \\
  \hline
  \bf 500.000 triplets & $7922 ms$  & $7076 ms$  \\
  \hline
\end{tabular}
\\\\
Considérons la variable $x_a$ associée à la mémoire ($x_a = -1$ pour $4GB$ et $x_a = 1$ pour $8GB$) et la variable $x_b$ associée à la taille de la donnée ($x_b = -1$ pour $100.000$ triplets et $x_b = 1$ pour $500.000$ triplets).\\
Le modèle de la non régréssion linéaire :
\begin{center}
  $y=q_0+q_a.x_a+q_b.x_b+q_{ab}.x_a.x_b$
\end{center}
Dans le cas du (low,low) ce qui revient à dire une mémoire de 4GB et une taille de données de $100.000$ triplets, on a :
\begin{center}
  $1569=q_0-q_a-q_b+q_{ab}$
\end{center}
Dans le cas du (high,low) ce qui revient à dire une mémoire de 8GB et une taille de données de $100.000$ triplets, on a :
\begin{center}
  $1669=q_0+q_a-q_b-q_{ab}$
\end{center}
Dans le cas du (low,high) ce qui revient à dire une mémoire de 4GB et une taille de données de $500.000$ triplets, on a :
\begin{center}
  $7922=q_0-q_a+q_b-q_{ab}$
\end{center}
Dans le cas du (high,high) ce qui revient à dire une mémoire de 8GB et une taille de données de $500.000$ triplets, on a :
\begin{center}
  $7076=q_0+q_a+q_b+q_{ab}$
\end{center}
Obtient donc :
\begin{center}
  $1569=q_0-q_a-q_b+q_{ab}$\\
  $1669=q_0+q_a-q_b-q_{ab}$\\
  $7922=q_0-q_a+q_b-q_{ab}$\\
  $7076=q_0+q_a+q_b+q_{ab}$
\end{center}
Alors
\begin{center}
  $y=4559-86.5x_a+2940x_b-336,5x_{ab}$
\end{center}
Cette équation nous permet de déduire certaines propriétes de notre système :
\begin{itemize}
\item On remarque que l'effet de la variation de la mémoire sur le temps d'éxécution des requêtes est quasiment nulle et peut être considéré comme négligeable.
\item Par contre la variation de la taille du jeu de données peut être considéré comme le facteur principal dans la variation du temps d'éxecution.
\item l'intéraction entre les deux facteurs est aussi négligeable que la variation effectuée par la mémoire
\end{itemize}

Ensuite nous avons voulu faire un experiment factoriel avec $2^{4-1}$, avec 4 qui représente les facteurs cités dans la section «Les métriques» (CPU, RAM, Data size, OS) et 1 le facteurs parmi ceux précédemment cité dont on considérera qu'un seul niveau et qui se trouve être la CPU.
Pour réaliser cet experiment nous avons besoin d'un ordinateur sous Mac avec 4Go de RAM et un autre sous Ubuntu avec 8 GO de RAM afin d'avoir les résultats nécéssaire. Malheuresement nous n'avons à disposition aucun des deux matériels cité précédemment .
\newpage
\section{Représentation graphique des résultats}

\begin{center}
  Temps d'import des données de notre système, de celui de jena et de celui de Florient Dieu selon 4 types de configuration.
\end{center}
\begin{figure}[h]
  \centering
  \begin{tikzpicture}[]
    \begin{axis}[
        grid=major,
        width=15cm, height=7cm,
        grid style={dashed,gray!30},
        xlabel=Environnement d'exécution,
        ylabel=Temps d'exécution (ms),
        legend style={at={(0.5,-0.35)},anchor=north,legend columns=-1},
        log ticks with fixed point,
        symbolic x coords={4GoRAM/100K, 4GoRAM/500K, 8GoRAM/100K, 8GoRAM/500K},
        xtick=data,
        ybar,
        ymax=20000,
        bar width=7pt
      ]      
      \addplot[blue,fill] plot coordinates {(4GoRAM/100K, 100000) (4GoRAM/500K,100000) (8GoRAM/100K,258107) (8GoRAM/500K,100000)};
      \addplot[green,fill] plot coordinates {(4GoRAM/100K,2082) (4GoRAM/500K,9097) (8GoRAM/100K,1791) (8GoRAM/500K,6639)};
      \addplot[orange,fill] plot coordinates {(4GoRAM/100K,4628) (4GoRAM/500K,5450) (8GoRAM/100K,5641) (8GoRAM/500K,14078)};
      \legend{Notre app , Jena , F.Dieu app}
    \end{axis}
  \end{tikzpicture}
\end{figure}
\begin{center}
  \color{blue} Moyenne arithmétique de 3 temps sur 5
\end{center}
Ce premier graphique correspond au temps d'import des données dans le système de notre application, de celle de Florient Dieu et enfin celle de Jena. Nous remarquons clairement un temps beaucoup plus important pour notre application, qui dans tout les cas de figure, représentés ici, le temps d'import dépasse largement ceux des autres applications.
\newpage
\begin{center}
  Temps d'éxécution des 1200 requetes de notre système, de celui de jena et de celui de Florient Dieu selon 4 types de configuration.
\end{center}
\begin{figure}[h]
  \centering
  \begin{tikzpicture}[]
    \begin{axis}[
        grid=major,
        width=15cm, height=7cm,
        grid style={dashed,gray!30},
        xlabel=Environnement d'exécution,
        ylabel=Temps d'exécution (ms),
        legend style={at={(0.5,-0.35)},anchor=north,legend columns=-1},
        log ticks with fixed point,
        symbolic x coords={4GoRAM/100K, 4GoRAM/500K, 8GoRAM/100K, 8GoRAM/500K},
        xtick=data,
        ybar,
        bar width=7pt
      ]      
      \addplot[blue,fill] plot coordinates {(4GoRAM/100K,1569) (4GoRAM/500K,7922) (8GoRAM/100K,1669) (8GoRAM/500K,7076)};
      \addplot[green,fill] plot coordinates {(4GoRAM/100K,363) (4GoRAM/500K,959) (8GoRAM/100K,1487) (8GoRAM/500K,2143)};
      \addplot[orange,fill] plot coordinates {(4GoRAM/100K,527) (4GoRAM/500K,583) (8GoRAM/100K,736) (8GoRAM/500K,2416)};
      \legend{Notre app , Jena , F.Dieu app}
    \end{axis}
  \end{tikzpicture}
\end{figure}
\begin{center}
  \color{blue} Moyenne arithmétique de 3 temps sur 5
\end{center}
Le deuxième graphique correspond aux temps d'executions des requêtes de notre application, de celle de Florient Dieu et enfin celle de Jena. Nous remarquons que  la taille de données a beaucoup d'importances dans les résultats. En effet les requêtes sur 100.000 triplets prennent moins de temps que sur les 500.000.\\
Pour les 100.000 triplets nous remarquons aussi que le temps d'éxecution des requêtes prend un peu plus de temps pour notre application comparés aux autres, mais reste quand même assez proche. Contrairement à quand nous les éxécutons sur 500.000 triplets, où là on a une différence plus flagrante.
\section{Conclusion}
Nous avons eu comme objectif dès le départ, d'essayer d'optimiser les approches graphes vu en cours afin de réaliser un mini-moteur rdf le plus performant possible. Nous avons eu une idée d'optimisation, que nous pensions performante. Nous l'avons implémenté pour ce projet, malheuresement les résultats obtenues étaient en dessous de nos prévisions avec une performance en deesous des applications avec lesquelles nous l'avons comparé.\\
La question à se poser maintenant est pourquoi cette optimisation, que nous pensions éfficace, se retrouve être moins intéréssante que les autres proposées. 
\end{document}
